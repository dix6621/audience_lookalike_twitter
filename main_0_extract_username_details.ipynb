{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8eb9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import functions_transform\n",
    "import functions_twitter\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8471a1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1 - 300\n"
     ]
    }
   ],
   "source": [
    "# Read input.csv with interested twitter_username.\n",
    "input_df = pd.read_csv(f'input.csv', index_col = 0)\n",
    "\n",
    "# Standardise all twitter_username to lowercase.\n",
    "input_df['twitter_username'] = input_df['twitter_username'].apply(lambda x: x.lower() if type(x) == str else x)\n",
    "\n",
    "# Extract twitter_username from input_df and remove NaN.\n",
    "twitter_socials = input_df['twitter_username'].dropna()\n",
    "\n",
    "# Extract all unique twitter_usernames and put them into a list\n",
    "unique_twitter_users = list(dict.fromkeys(list(twitter_socials)))\n",
    "\n",
    "# group unique_twitter_usernames into batch of 100s and convert them into chunks of strings\n",
    "user_groups = list(functions_transform.chunks(unique_twitter_users, 100))\n",
    "user_strings, counts = functions_transform.string_chunks(user_groups)\n",
    "\n",
    "# Read list of secrets. Due to rate limit, multiple twitter developer accounts are recommended.\n",
    "secrets_pool = pd.read_csv('twitter_dev_secrets.csv', index_col = False)\n",
    "bearer_tokens = list(secrets_pool['bearer_token'])\n",
    "\n",
    "# Select first token on the list to start requests\n",
    "# auth_header = {'Authorization' : f'Bearer {bearer_tokens[0]}'}\n",
    "\n",
    "bearer_tokens_catridge = bearer_tokens.copy()\n",
    "bearer_token = bearer_tokens_catridge.pop(0)\n",
    "rate_limit_reset_time = time.mktime(datetime.datetime.now().timetuple()) + 1000 # timestamp when bearer_token_catridge restarted\n",
    "\n",
    "# user_fields = 'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld'\n",
    "user_fields = 'created_at,id,public_metrics,username,verified'\n",
    "\n",
    "# Call Twitter API to extract username info\n",
    "users_data = []\n",
    "users_errors = []\n",
    "total_batch = len(user_strings)\n",
    "request_left = 300\n",
    "for i, user_string in enumerate(user_strings):\n",
    "    print(f'{i} / {total_batch} - {request_left}')\n",
    "    nxt_page = True\n",
    "    while nxt_page:\n",
    "        if request_left > 0:\n",
    "            request, request_left = functions_twitter.twitter_get_users_by_usernames(user_string, bearer_token, user_fields)\n",
    "            if request.status_code == 200:\n",
    "                request_json = request.json()\n",
    "                if 'errors' in request_json.keys():\n",
    "                    users_errors += request_json['errors']\n",
    "                else:\n",
    "                    users_data += request_json['data']\n",
    "            else:\n",
    "                print('gg')\n",
    "            nxt_page = False\n",
    "        else:\n",
    "            request_reset_unixtime = float(request.headers['x-rate-limit-reset']) # timestamp when the request limit for bearer token is expected to reset.\n",
    "            rate_limit_reset_time = min(request_reset_unixtime,rate_limit_reset_time)\n",
    "            bearer_tokens_catridge, bearer_token, request_left, rate_limit_reset_time = functions_twitter.catridge_reset(rate_limit_reset_time, bearer_tokens_catridge, bearer_tokens, 300)\n",
    "            \n",
    "users_data_df = pd.json_normalize(users_data)\n",
    "users_errors_df = pd.json_normalize(users_errors)\n",
    "\n",
    "# Convert users_data_df.created_at from string to datetime.\n",
    "users_data_df['created_at'] = pd.to_datetime(users_data_df['created_at']).dt.strftime('%Y-%m-%d')\n",
    "users_data_df['created_at'] = users_data_df['created_at'].apply(lambda x: datetime.datetime.strptime(x,'%Y-%m-%d'))\n",
    "\n",
    "today = datetime.datetime.today()\n",
    "\n",
    "# Add column 'days_since_inception' to users_data_df - Number of days since inception of twitter_username\n",
    "users_data_df['days_since_inception'] = users_data_df['created_at'].apply(lambda x: (today - x).days)\n",
    "\n",
    "# Add column 'rate_of_tweet_count' to users_data_df - Weekly average tweet_count since inception\n",
    "users_data_df['wkly_avg_tweet_count'] = users_data_df['public_metrics.tweet_count']*7/(users_data_df['days_since_inception'])\n",
    "\n",
    "# Add column 'rate_of_follower_count' to users_data_df - Daily average growth of follower count since inception\n",
    "users_data_df['daily_avg_growth_follower_count'] = users_data_df['public_metrics.followers_count']/users_data_df['days_since_inception']\n",
    "\n",
    "# Add column 'rate_of_listed_count' to users_data_df - Daily average growth of listed count since inception\n",
    "users_data_df['daily_avg_growth_listed_count'] = users_data_df['public_metrics.listed_count']/users_data_df['days_since_inception']\n",
    "\n",
    "# Export users_data_df into csv\n",
    "users_data_df.sort_values('daily_avg_growth_listed_count', ascending = False, inplace = True)\n",
    "users_data_df.reset_index(drop=True, inplace=True)\n",
    "users_data_df.to_csv(f'output_0/twitter_summary.tsv', sep = '\\t')\n",
    "\n",
    "# Export users_errors_df into csv\n",
    "users_errors_df.to_csv(f'output_0/twitter_errors.tsv', sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d134262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('lfb_spartan')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1760b9e0dee9eced2372190870f340939ddc88a195c9cdd127b7c20b118d7257"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
